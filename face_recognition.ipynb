{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/rcmalli/keras-vggface.git\n",
      "  Cloning https://github.com/rcmalli/keras-vggface.git to c:\\users\\pedro\\appdata\\local\\temp\\pip-req-build-gygnhsl0\n",
      "  Resolved https://github.com/rcmalli/keras-vggface.git to commit bee35376e76e35d00aeec503f2f242611a97b38a\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\python311\\lib\\site-packages (from keras-vggface==0.6) (1.25.2)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\python311\\lib\\site-packages (from keras-vggface==0.6) (1.11.2)\n",
      "Requirement already satisfied: h5py in c:\\python311\\lib\\site-packages (from keras-vggface==0.6) (3.9.0)\n",
      "Requirement already satisfied: pillow in c:\\python311\\lib\\site-packages (from keras-vggface==0.6) (10.0.0)\n",
      "Requirement already satisfied: keras in c:\\python311\\lib\\site-packages (from keras-vggface==0.6) (2.2.4)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\pedro\\appdata\\roaming\\python\\python311\\site-packages (from keras-vggface==0.6) (1.16.0)\n",
      "Requirement already satisfied: pyyaml in c:\\python311\\lib\\site-packages (from keras-vggface==0.6) (6.0.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\python311\\lib\\site-packages (from keras->keras-vggface==0.6) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\python311\\lib\\site-packages (from keras->keras-vggface==0.6) (1.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/rcmalli/keras-vggface.git 'C:\\Users\\pedro\\AppData\\Local\\Temp\\pip-req-build-gygnhsl0'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras==2.2.4 in c:\\python311\\lib\\site-packages (2.2.4)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\python311\\lib\\site-packages (from keras==2.2.4) (1.25.2)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\python311\\lib\\site-packages (from keras==2.2.4) (1.11.2)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\pedro\\appdata\\roaming\\python\\python311\\site-packages (from keras==2.2.4) (1.16.0)\n",
      "Requirement already satisfied: pyyaml in c:\\python311\\lib\\site-packages (from keras==2.2.4) (6.0.1)\n",
      "Requirement already satisfied: h5py in c:\\python311\\lib\\site-packages (from keras==2.2.4) (3.9.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\python311\\lib\\site-packages (from keras==2.2.4) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\python311\\lib\\site-packages (from keras==2.2.4) (1.1.2)\n"
     ]
    }
   ],
   "source": [
    "%pip install git+https://github.com/rcmalli/keras-vggface.git\n",
    "%pip install keras==2.2.4\n",
    "# %pip install tensorflow==1.14.0\n",
    "from keras_vggface.vggface import VGGFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "vggface = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3)) # or VGGFace() as default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x00000284864C5760> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function trace_model_call.<locals>._wrapped_model at 0x00000284864C5760>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x00000284864C5760> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function trace_model_call.<locals>._wrapped_model at 0x00000284864C5760>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x00000284864C5760> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function trace_model_call.<locals>._wrapped_model at 0x00000284864C5760>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: resnet_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: resnet_model\\assets\n"
     ]
    }
   ],
   "source": [
    "vggface.save('resnet_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# model = tf.keras.applications.resnet50.ResNet50(include_top=False, weights=None)\n",
    "mod = tf.keras.models.load_model('resnet_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_class = 2\n",
    "hidden_dim = 512\n",
    "# seq = tf.keras.Sequential(mod)\n",
    "\n",
    "last_layer = mod.get_layer('avg_pool').output\n",
    "x = tf.keras.layers.Flatten(name='flatten')(last_layer)\n",
    "x = tf.keras.layers.Dense(hidden_dim, activation='relu', name='fc6')(x)\n",
    "x = tf.keras.layers.Dense(hidden_dim, activation='relu', name='fc7')(x)\n",
    "out = tf.keras.layers.Dense(nb_class, activation='softmax', name='fc8')(x)\n",
    "\n",
    "custom_vgg_model = tf.keras.Model(mod.input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_17 (InputLayer)       [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv1/7x7_s2 (Conv2D)       (None, 112, 112, 64)         9408      ['input_17[0][0]']            \n",
      "                                                                                                  \n",
      " conv1/7x7_s2/bn (BatchNorm  (None, 112, 112, 64)         256       ['conv1/7x7_s2[0][0]']        \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation_441 (Activation  (None, 112, 112, 64)         0         ['conv1/7x7_s2/bn[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPoolin  (None, 55, 55, 64)           0         ['activation_441[0][0]']      \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_1_1x1_reduce (Conv2D  (None, 55, 55, 64)           4096      ['max_pooling2d_9[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_1_1x1_reduce/bn (Bat  (None, 55, 55, 64)           256       ['conv2_1_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_442 (Activation  (None, 55, 55, 64)           0         ['conv2_1_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv2_1_3x3 (Conv2D)        (None, 55, 55, 64)           36864     ['activation_442[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_1_3x3/bn (BatchNorma  (None, 55, 55, 64)           256       ['conv2_1_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_443 (Activation  (None, 55, 55, 64)           0         ['conv2_1_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_1_1x1_increase (Conv  (None, 55, 55, 256)          16384     ['activation_443[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv2_1_1x1_proj (Conv2D)   (None, 55, 55, 256)          16384     ['max_pooling2d_9[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_1_1x1_increase/bn (B  (None, 55, 55, 256)          1024      ['conv2_1_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2_1_1x1_proj/bn (Batch  (None, 55, 55, 256)          1024      ['conv2_1_1x1_proj[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_144 (Add)               (None, 55, 55, 256)          0         ['conv2_1_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'conv2_1_1x1_proj/bn[0][0]'] \n",
      "                                                                                                  \n",
      " activation_444 (Activation  (None, 55, 55, 256)          0         ['add_144[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_2_1x1_reduce (Conv2D  (None, 55, 55, 64)           16384     ['activation_444[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_2_1x1_reduce/bn (Bat  (None, 55, 55, 64)           256       ['conv2_2_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_445 (Activation  (None, 55, 55, 64)           0         ['conv2_2_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv2_2_3x3 (Conv2D)        (None, 55, 55, 64)           36864     ['activation_445[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_2_3x3/bn (BatchNorma  (None, 55, 55, 64)           256       ['conv2_2_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_446 (Activation  (None, 55, 55, 64)           0         ['conv2_2_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_2_1x1_increase (Conv  (None, 55, 55, 256)          16384     ['activation_446[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv2_2_1x1_increase/bn (B  (None, 55, 55, 256)          1024      ['conv2_2_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_145 (Add)               (None, 55, 55, 256)          0         ['conv2_2_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_444[0][0]']      \n",
      "                                                                                                  \n",
      " activation_447 (Activation  (None, 55, 55, 256)          0         ['add_145[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_3_1x1_reduce (Conv2D  (None, 55, 55, 64)           16384     ['activation_447[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_3_1x1_reduce/bn (Bat  (None, 55, 55, 64)           256       ['conv2_3_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_448 (Activation  (None, 55, 55, 64)           0         ['conv2_3_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv2_3_3x3 (Conv2D)        (None, 55, 55, 64)           36864     ['activation_448[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_3_3x3/bn (BatchNorma  (None, 55, 55, 64)           256       ['conv2_3_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_449 (Activation  (None, 55, 55, 64)           0         ['conv2_3_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_3_1x1_increase (Conv  (None, 55, 55, 256)          16384     ['activation_449[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv2_3_1x1_increase/bn (B  (None, 55, 55, 256)          1024      ['conv2_3_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_146 (Add)               (None, 55, 55, 256)          0         ['conv2_3_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_447[0][0]']      \n",
      "                                                                                                  \n",
      " activation_450 (Activation  (None, 55, 55, 256)          0         ['add_146[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_1_1x1_reduce (Conv2D  (None, 28, 28, 128)          32768     ['activation_450[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_1_1x1_reduce/bn (Bat  (None, 28, 28, 128)          512       ['conv3_1_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_451 (Activation  (None, 28, 28, 128)          0         ['conv3_1_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv3_1_3x3 (Conv2D)        (None, 28, 28, 128)          147456    ['activation_451[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_1_3x3/bn (BatchNorma  (None, 28, 28, 128)          512       ['conv3_1_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_452 (Activation  (None, 28, 28, 128)          0         ['conv3_1_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_1_1x1_increase (Conv  (None, 28, 28, 512)          65536     ['activation_452[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_1_1x1_proj (Conv2D)   (None, 28, 28, 512)          131072    ['activation_450[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_1_1x1_increase/bn (B  (None, 28, 28, 512)          2048      ['conv3_1_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv3_1_1x1_proj/bn (Batch  (None, 28, 28, 512)          2048      ['conv3_1_1x1_proj[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_147 (Add)               (None, 28, 28, 512)          0         ['conv3_1_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'conv3_1_1x1_proj/bn[0][0]'] \n",
      "                                                                                                  \n",
      " activation_453 (Activation  (None, 28, 28, 512)          0         ['add_147[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_2_1x1_reduce (Conv2D  (None, 28, 28, 128)          65536     ['activation_453[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_2_1x1_reduce/bn (Bat  (None, 28, 28, 128)          512       ['conv3_2_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_454 (Activation  (None, 28, 28, 128)          0         ['conv3_2_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv3_2_3x3 (Conv2D)        (None, 28, 28, 128)          147456    ['activation_454[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_2_3x3/bn (BatchNorma  (None, 28, 28, 128)          512       ['conv3_2_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_455 (Activation  (None, 28, 28, 128)          0         ['conv3_2_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_2_1x1_increase (Conv  (None, 28, 28, 512)          65536     ['activation_455[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_2_1x1_increase/bn (B  (None, 28, 28, 512)          2048      ['conv3_2_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_148 (Add)               (None, 28, 28, 512)          0         ['conv3_2_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_453[0][0]']      \n",
      "                                                                                                  \n",
      " activation_456 (Activation  (None, 28, 28, 512)          0         ['add_148[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_3_1x1_reduce (Conv2D  (None, 28, 28, 128)          65536     ['activation_456[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_3_1x1_reduce/bn (Bat  (None, 28, 28, 128)          512       ['conv3_3_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_457 (Activation  (None, 28, 28, 128)          0         ['conv3_3_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv3_3_3x3 (Conv2D)        (None, 28, 28, 128)          147456    ['activation_457[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_3_3x3/bn (BatchNorma  (None, 28, 28, 128)          512       ['conv3_3_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_458 (Activation  (None, 28, 28, 128)          0         ['conv3_3_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_3_1x1_increase (Conv  (None, 28, 28, 512)          65536     ['activation_458[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_3_1x1_increase/bn (B  (None, 28, 28, 512)          2048      ['conv3_3_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_149 (Add)               (None, 28, 28, 512)          0         ['conv3_3_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_456[0][0]']      \n",
      "                                                                                                  \n",
      " activation_459 (Activation  (None, 28, 28, 512)          0         ['add_149[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_4_1x1_reduce (Conv2D  (None, 28, 28, 128)          65536     ['activation_459[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_4_1x1_reduce/bn (Bat  (None, 28, 28, 128)          512       ['conv3_4_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_460 (Activation  (None, 28, 28, 128)          0         ['conv3_4_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv3_4_3x3 (Conv2D)        (None, 28, 28, 128)          147456    ['activation_460[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_4_3x3/bn (BatchNorma  (None, 28, 28, 128)          512       ['conv3_4_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_461 (Activation  (None, 28, 28, 128)          0         ['conv3_4_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_4_1x1_increase (Conv  (None, 28, 28, 512)          65536     ['activation_461[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_4_1x1_increase/bn (B  (None, 28, 28, 512)          2048      ['conv3_4_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_150 (Add)               (None, 28, 28, 512)          0         ['conv3_4_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_459[0][0]']      \n",
      "                                                                                                  \n",
      " activation_462 (Activation  (None, 28, 28, 512)          0         ['add_150[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_1_1x1_reduce (Conv2D  (None, 14, 14, 256)          131072    ['activation_462[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_1_1x1_reduce/bn (Bat  (None, 14, 14, 256)          1024      ['conv4_1_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_463 (Activation  (None, 14, 14, 256)          0         ['conv4_1_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv4_1_3x3 (Conv2D)        (None, 14, 14, 256)          589824    ['activation_463[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_1_3x3/bn (BatchNorma  (None, 14, 14, 256)          1024      ['conv4_1_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_464 (Activation  (None, 14, 14, 256)          0         ['conv4_1_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_1_1x1_increase (Conv  (None, 14, 14, 1024)         262144    ['activation_464[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_1_1x1_proj (Conv2D)   (None, 14, 14, 1024)         524288    ['activation_462[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_1_1x1_increase/bn (B  (None, 14, 14, 1024)         4096      ['conv4_1_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv4_1_1x1_proj/bn (Batch  (None, 14, 14, 1024)         4096      ['conv4_1_1x1_proj[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_151 (Add)               (None, 14, 14, 1024)         0         ['conv4_1_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'conv4_1_1x1_proj/bn[0][0]'] \n",
      "                                                                                                  \n",
      " activation_465 (Activation  (None, 14, 14, 1024)         0         ['add_151[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_2_1x1_reduce (Conv2D  (None, 14, 14, 256)          262144    ['activation_465[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_2_1x1_reduce/bn (Bat  (None, 14, 14, 256)          1024      ['conv4_2_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_466 (Activation  (None, 14, 14, 256)          0         ['conv4_2_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv4_2_3x3 (Conv2D)        (None, 14, 14, 256)          589824    ['activation_466[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_2_3x3/bn (BatchNorma  (None, 14, 14, 256)          1024      ['conv4_2_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_467 (Activation  (None, 14, 14, 256)          0         ['conv4_2_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_2_1x1_increase (Conv  (None, 14, 14, 1024)         262144    ['activation_467[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_2_1x1_increase/bn (B  (None, 14, 14, 1024)         4096      ['conv4_2_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_152 (Add)               (None, 14, 14, 1024)         0         ['conv4_2_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_465[0][0]']      \n",
      "                                                                                                  \n",
      " activation_468 (Activation  (None, 14, 14, 1024)         0         ['add_152[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_3_1x1_reduce (Conv2D  (None, 14, 14, 256)          262144    ['activation_468[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_3_1x1_reduce/bn (Bat  (None, 14, 14, 256)          1024      ['conv4_3_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_469 (Activation  (None, 14, 14, 256)          0         ['conv4_3_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv4_3_3x3 (Conv2D)        (None, 14, 14, 256)          589824    ['activation_469[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_3_3x3/bn (BatchNorma  (None, 14, 14, 256)          1024      ['conv4_3_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_470 (Activation  (None, 14, 14, 256)          0         ['conv4_3_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_3_1x1_increase (Conv  (None, 14, 14, 1024)         262144    ['activation_470[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_3_1x1_increase/bn (B  (None, 14, 14, 1024)         4096      ['conv4_3_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_153 (Add)               (None, 14, 14, 1024)         0         ['conv4_3_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_468[0][0]']      \n",
      "                                                                                                  \n",
      " activation_471 (Activation  (None, 14, 14, 1024)         0         ['add_153[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_4_1x1_reduce (Conv2D  (None, 14, 14, 256)          262144    ['activation_471[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_4_1x1_reduce/bn (Bat  (None, 14, 14, 256)          1024      ['conv4_4_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_472 (Activation  (None, 14, 14, 256)          0         ['conv4_4_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv4_4_3x3 (Conv2D)        (None, 14, 14, 256)          589824    ['activation_472[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_4_3x3/bn (BatchNorma  (None, 14, 14, 256)          1024      ['conv4_4_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_473 (Activation  (None, 14, 14, 256)          0         ['conv4_4_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_4_1x1_increase (Conv  (None, 14, 14, 1024)         262144    ['activation_473[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_4_1x1_increase/bn (B  (None, 14, 14, 1024)         4096      ['conv4_4_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_154 (Add)               (None, 14, 14, 1024)         0         ['conv4_4_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_471[0][0]']      \n",
      "                                                                                                  \n",
      " activation_474 (Activation  (None, 14, 14, 1024)         0         ['add_154[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_5_1x1_reduce (Conv2D  (None, 14, 14, 256)          262144    ['activation_474[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_5_1x1_reduce/bn (Bat  (None, 14, 14, 256)          1024      ['conv4_5_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_475 (Activation  (None, 14, 14, 256)          0         ['conv4_5_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv4_5_3x3 (Conv2D)        (None, 14, 14, 256)          589824    ['activation_475[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_5_3x3/bn (BatchNorma  (None, 14, 14, 256)          1024      ['conv4_5_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_476 (Activation  (None, 14, 14, 256)          0         ['conv4_5_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_5_1x1_increase (Conv  (None, 14, 14, 1024)         262144    ['activation_476[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_5_1x1_increase/bn (B  (None, 14, 14, 1024)         4096      ['conv4_5_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_155 (Add)               (None, 14, 14, 1024)         0         ['conv4_5_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_474[0][0]']      \n",
      "                                                                                                  \n",
      " activation_477 (Activation  (None, 14, 14, 1024)         0         ['add_155[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_6_1x1_reduce (Conv2D  (None, 14, 14, 256)          262144    ['activation_477[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_6_1x1_reduce/bn (Bat  (None, 14, 14, 256)          1024      ['conv4_6_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_478 (Activation  (None, 14, 14, 256)          0         ['conv4_6_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv4_6_3x3 (Conv2D)        (None, 14, 14, 256)          589824    ['activation_478[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_6_3x3/bn (BatchNorma  (None, 14, 14, 256)          1024      ['conv4_6_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_479 (Activation  (None, 14, 14, 256)          0         ['conv4_6_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_6_1x1_increase (Conv  (None, 14, 14, 1024)         262144    ['activation_479[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_6_1x1_increase/bn (B  (None, 14, 14, 1024)         4096      ['conv4_6_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_156 (Add)               (None, 14, 14, 1024)         0         ['conv4_6_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_477[0][0]']      \n",
      "                                                                                                  \n",
      " activation_480 (Activation  (None, 14, 14, 1024)         0         ['add_156[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_1_1x1_reduce (Conv2D  (None, 7, 7, 512)            524288    ['activation_480[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_1_1x1_reduce/bn (Bat  (None, 7, 7, 512)            2048      ['conv5_1_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_481 (Activation  (None, 7, 7, 512)            0         ['conv5_1_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv5_1_3x3 (Conv2D)        (None, 7, 7, 512)            2359296   ['activation_481[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_1_3x3/bn (BatchNorma  (None, 7, 7, 512)            2048      ['conv5_1_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_482 (Activation  (None, 7, 7, 512)            0         ['conv5_1_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_1_1x1_increase (Conv  (None, 7, 7, 2048)           1048576   ['activation_482[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_1_1x1_proj (Conv2D)   (None, 7, 7, 2048)           2097152   ['activation_480[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_1_1x1_increase/bn (B  (None, 7, 7, 2048)           8192      ['conv5_1_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv5_1_1x1_proj/bn (Batch  (None, 7, 7, 2048)           8192      ['conv5_1_1x1_proj[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_157 (Add)               (None, 7, 7, 2048)           0         ['conv5_1_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'conv5_1_1x1_proj/bn[0][0]'] \n",
      "                                                                                                  \n",
      " activation_483 (Activation  (None, 7, 7, 2048)           0         ['add_157[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_2_1x1_reduce (Conv2D  (None, 7, 7, 512)            1048576   ['activation_483[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_2_1x1_reduce/bn (Bat  (None, 7, 7, 512)            2048      ['conv5_2_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_484 (Activation  (None, 7, 7, 512)            0         ['conv5_2_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv5_2_3x3 (Conv2D)        (None, 7, 7, 512)            2359296   ['activation_484[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_2_3x3/bn (BatchNorma  (None, 7, 7, 512)            2048      ['conv5_2_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_485 (Activation  (None, 7, 7, 512)            0         ['conv5_2_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_2_1x1_increase (Conv  (None, 7, 7, 2048)           1048576   ['activation_485[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_2_1x1_increase/bn (B  (None, 7, 7, 2048)           8192      ['conv5_2_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_158 (Add)               (None, 7, 7, 2048)           0         ['conv5_2_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_483[0][0]']      \n",
      "                                                                                                  \n",
      " activation_486 (Activation  (None, 7, 7, 2048)           0         ['add_158[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_3_1x1_reduce (Conv2D  (None, 7, 7, 512)            1048576   ['activation_486[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_3_1x1_reduce/bn (Bat  (None, 7, 7, 512)            2048      ['conv5_3_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_487 (Activation  (None, 7, 7, 512)            0         ['conv5_3_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv5_3_3x3 (Conv2D)        (None, 7, 7, 512)            2359296   ['activation_487[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_3_3x3/bn (BatchNorma  (None, 7, 7, 512)            2048      ['conv5_3_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_488 (Activation  (None, 7, 7, 512)            0         ['conv5_3_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_3_1x1_increase (Conv  (None, 7, 7, 2048)           1048576   ['activation_488[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_3_1x1_increase/bn (B  (None, 7, 7, 2048)           8192      ['conv5_3_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_159 (Add)               (None, 7, 7, 2048)           0         ['conv5_3_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_486[0][0]']      \n",
      "                                                                                                  \n",
      " activation_489 (Activation  (None, 7, 7, 2048)           0         ['add_159[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " avg_pool (AveragePooling2D  (None, 1, 1, 2048)           0         ['activation_489[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 2048)                 0         ['avg_pool[0][0]']            \n",
      "                                                                                                  \n",
      " fc6 (Dense)                 (None, 512)                  1049088   ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " fc7 (Dense)                 (None, 512)                  262656    ['fc6[0][0]']                 \n",
      "                                                                                                  \n",
      " fc8 (Dense)                 (None, 2)                    1026      ['fc7[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 24873922 (94.89 MB)\n",
      "Trainable params: 24820802 (94.68 MB)\n",
      "Non-trainable params: 53120 (207.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "custom_vgg_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinar inicialmente com todos as camadas treinaveis\n",
    "Para adicionar novas pessoas, adicionar uma classe extra na camada final e treinar apenas a ultima camada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "im = cv2.imread('lacto.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_pro = tf.keras.applications.vgg19.preprocess_input(\n",
    "    im, data_format=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2416, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2401, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2389, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2357, in predict_step\n        return self(x, training=False)\n    File \"c:\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"vgg19\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(32, 768, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pedro\\OneDrive\\Documentos\\GitHub\\FaceRecognition_FeatureExtractor\\face_recognition.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/pedro/OneDrive/Documentos/GitHub/FaceRecognition_FeatureExtractor/face_recognition.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mpredict(im_pro)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filevln9fvrr.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2416, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2401, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2389, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2357, in predict_step\n        return self(x, training=False)\n    File \"c:\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"vgg19\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(32, 768, 3)\n"
     ]
    }
   ],
   "source": [
    "model.predict(im_pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/rcmalli/keras-vggface.git\n",
      "  Cloning https://github.com/rcmalli/keras-vggface.git to c:\\users\\pedro\\appdata\\local\\temp\\pip-req-build-f94j__8a\n",
      "  Resolved https://github.com/rcmalli/keras-vggface.git to commit bee35376e76e35d00aeec503f2f242611a97b38a\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\python311\\lib\\site-packages (from keras-vggface==0.6) (1.25.2)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\python311\\lib\\site-packages (from keras-vggface==0.6) (1.11.2)\n",
      "Requirement already satisfied: h5py in c:\\python311\\lib\\site-packages (from keras-vggface==0.6) (3.9.0)\n",
      "Requirement already satisfied: pillow in c:\\python311\\lib\\site-packages (from keras-vggface==0.6) (10.0.0)\n",
      "Requirement already satisfied: keras in c:\\python311\\lib\\site-packages (from keras-vggface==0.6) (2.2.4)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\pedro\\appdata\\roaming\\python\\python311\\site-packages (from keras-vggface==0.6) (1.16.0)\n",
      "Requirement already satisfied: pyyaml in c:\\python311\\lib\\site-packages (from keras-vggface==0.6) (6.0.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\python311\\lib\\site-packages (from keras->keras-vggface==0.6) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\python311\\lib\\site-packages (from keras->keras-vggface==0.6) (1.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/rcmalli/keras-vggface.git 'C:\\Users\\pedro\\AppData\\Local\\Temp\\pip-req-build-f94j__8a'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras==2.2.4 in c:\\python311\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\python311\\lib\\site-packages (from keras==2.2.4) (1.25.2)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\python311\\lib\\site-packages (from keras==2.2.4) (1.11.2)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\pedro\\appdata\\roaming\\python\\python311\\site-packages (from keras==2.2.4) (1.16.0)\n",
      "Requirement already satisfied: pyyaml in c:\\python311\\lib\\site-packages (from keras==2.2.4) (6.0.1)\n",
      "Requirement already satisfied: h5py in c:\\python311\\lib\\site-packages (from keras==2.2.4) (3.9.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\python311\\lib\\site-packages (from keras==2.2.4) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\python311\\lib\\site-packages (from keras==2.2.4) (1.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow==1.14.0 (from versions: 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.15.0rc0, 2.15.0rc1)\n",
      "ERROR: No matching distribution found for tensorflow==1.14.0\n"
     ]
    }
   ],
   "source": [
    "%pip install git+https://github.com/rcmalli/keras-vggface.git\n",
    "%pip install keras==2.2.4\n",
    "%pip install tensorflow==1.14.0\n",
    "from keras_vggface.vggface import VGGFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_resnet50.h5\n",
      "165445632/165439116 [==============================] - 6s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Finetuning\n",
    "vggface = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3)) # or VGGFace() as default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x000002846F450180> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function trace_model_call.<locals>._wrapped_model at 0x000002846F450180>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x000002846F450180> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function trace_model_call.<locals>._wrapped_model at 0x000002846F450180>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: test.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: test.tf\\assets\n"
     ]
    }
   ],
   "source": [
    "vggface.save('test.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vggface_resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv1/7x7_s2 (Conv2D)       (None, 112, 112, 64)         9408      ['input_5[0][0]']             \n",
      "                                                                                                  \n",
      " conv1/7x7_s2/bn (BatchNorm  (None, 112, 112, 64)         256       ['conv1/7x7_s2[0][0]']        \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation_49 (Activation)  (None, 112, 112, 64)         0         ['conv1/7x7_s2/bn[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 55, 55, 64)           0         ['activation_49[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_1_1x1_reduce (Conv2D  (None, 55, 55, 64)           4096      ['max_pooling2d_1[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_1_1x1_reduce/bn (Bat  (None, 55, 55, 64)           256       ['conv2_1_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_50 (Activation)  (None, 55, 55, 64)           0         ['conv2_1_1x1_reduce/bn[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2_1_3x3 (Conv2D)        (None, 55, 55, 64)           36864     ['activation_50[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_1_3x3/bn (BatchNorma  (None, 55, 55, 64)           256       ['conv2_1_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_51 (Activation)  (None, 55, 55, 64)           0         ['conv2_1_3x3/bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_1_1x1_increase (Conv  (None, 55, 55, 256)          16384     ['activation_51[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv2_1_1x1_proj (Conv2D)   (None, 55, 55, 256)          16384     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_1_1x1_increase/bn (B  (None, 55, 55, 256)          1024      ['conv2_1_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2_1_1x1_proj/bn (Batch  (None, 55, 55, 256)          1024      ['conv2_1_1x1_proj[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_16 (Add)                (None, 55, 55, 256)          0         ['conv2_1_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'conv2_1_1x1_proj/bn[0][0]'] \n",
      "                                                                                                  \n",
      " activation_52 (Activation)  (None, 55, 55, 256)          0         ['add_16[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_2_1x1_reduce (Conv2D  (None, 55, 55, 64)           16384     ['activation_52[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_2_1x1_reduce/bn (Bat  (None, 55, 55, 64)           256       ['conv2_2_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_53 (Activation)  (None, 55, 55, 64)           0         ['conv2_2_1x1_reduce/bn[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2_2_3x3 (Conv2D)        (None, 55, 55, 64)           36864     ['activation_53[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_2_3x3/bn (BatchNorma  (None, 55, 55, 64)           256       ['conv2_2_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_54 (Activation)  (None, 55, 55, 64)           0         ['conv2_2_3x3/bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_2_1x1_increase (Conv  (None, 55, 55, 256)          16384     ['activation_54[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv2_2_1x1_increase/bn (B  (None, 55, 55, 256)          1024      ['conv2_2_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_17 (Add)                (None, 55, 55, 256)          0         ['conv2_2_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_52[0][0]']       \n",
      "                                                                                                  \n",
      " activation_55 (Activation)  (None, 55, 55, 256)          0         ['add_17[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_3_1x1_reduce (Conv2D  (None, 55, 55, 64)           16384     ['activation_55[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_3_1x1_reduce/bn (Bat  (None, 55, 55, 64)           256       ['conv2_3_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_56 (Activation)  (None, 55, 55, 64)           0         ['conv2_3_1x1_reduce/bn[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2_3_3x3 (Conv2D)        (None, 55, 55, 64)           36864     ['activation_56[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_3_3x3/bn (BatchNorma  (None, 55, 55, 64)           256       ['conv2_3_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_57 (Activation)  (None, 55, 55, 64)           0         ['conv2_3_3x3/bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_3_1x1_increase (Conv  (None, 55, 55, 256)          16384     ['activation_57[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv2_3_1x1_increase/bn (B  (None, 55, 55, 256)          1024      ['conv2_3_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_18 (Add)                (None, 55, 55, 256)          0         ['conv2_3_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_55[0][0]']       \n",
      "                                                                                                  \n",
      " activation_58 (Activation)  (None, 55, 55, 256)          0         ['add_18[0][0]']              \n",
      "                                                                                                  \n",
      " conv3_1_1x1_reduce (Conv2D  (None, 28, 28, 128)          32768     ['activation_58[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_1_1x1_reduce/bn (Bat  (None, 28, 28, 128)          512       ['conv3_1_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_59 (Activation)  (None, 28, 28, 128)          0         ['conv3_1_1x1_reduce/bn[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv3_1_3x3 (Conv2D)        (None, 28, 28, 128)          147456    ['activation_59[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_1_3x3/bn (BatchNorma  (None, 28, 28, 128)          512       ['conv3_1_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_60 (Activation)  (None, 28, 28, 128)          0         ['conv3_1_3x3/bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_1_1x1_increase (Conv  (None, 28, 28, 512)          65536     ['activation_60[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_1_1x1_proj (Conv2D)   (None, 28, 28, 512)          131072    ['activation_58[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_1_1x1_increase/bn (B  (None, 28, 28, 512)          2048      ['conv3_1_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv3_1_1x1_proj/bn (Batch  (None, 28, 28, 512)          2048      ['conv3_1_1x1_proj[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_19 (Add)                (None, 28, 28, 512)          0         ['conv3_1_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'conv3_1_1x1_proj/bn[0][0]'] \n",
      "                                                                                                  \n",
      " activation_61 (Activation)  (None, 28, 28, 512)          0         ['add_19[0][0]']              \n",
      "                                                                                                  \n",
      " conv3_2_1x1_reduce (Conv2D  (None, 28, 28, 128)          65536     ['activation_61[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_2_1x1_reduce/bn (Bat  (None, 28, 28, 128)          512       ['conv3_2_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_62 (Activation)  (None, 28, 28, 128)          0         ['conv3_2_1x1_reduce/bn[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv3_2_3x3 (Conv2D)        (None, 28, 28, 128)          147456    ['activation_62[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_2_3x3/bn (BatchNorma  (None, 28, 28, 128)          512       ['conv3_2_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_63 (Activation)  (None, 28, 28, 128)          0         ['conv3_2_3x3/bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_2_1x1_increase (Conv  (None, 28, 28, 512)          65536     ['activation_63[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_2_1x1_increase/bn (B  (None, 28, 28, 512)          2048      ['conv3_2_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_20 (Add)                (None, 28, 28, 512)          0         ['conv3_2_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_61[0][0]']       \n",
      "                                                                                                  \n",
      " activation_64 (Activation)  (None, 28, 28, 512)          0         ['add_20[0][0]']              \n",
      "                                                                                                  \n",
      " conv3_3_1x1_reduce (Conv2D  (None, 28, 28, 128)          65536     ['activation_64[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_3_1x1_reduce/bn (Bat  (None, 28, 28, 128)          512       ['conv3_3_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_65 (Activation)  (None, 28, 28, 128)          0         ['conv3_3_1x1_reduce/bn[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv3_3_3x3 (Conv2D)        (None, 28, 28, 128)          147456    ['activation_65[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_3_3x3/bn (BatchNorma  (None, 28, 28, 128)          512       ['conv3_3_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_66 (Activation)  (None, 28, 28, 128)          0         ['conv3_3_3x3/bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_3_1x1_increase (Conv  (None, 28, 28, 512)          65536     ['activation_66[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_3_1x1_increase/bn (B  (None, 28, 28, 512)          2048      ['conv3_3_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_21 (Add)                (None, 28, 28, 512)          0         ['conv3_3_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_64[0][0]']       \n",
      "                                                                                                  \n",
      " activation_67 (Activation)  (None, 28, 28, 512)          0         ['add_21[0][0]']              \n",
      "                                                                                                  \n",
      " conv3_4_1x1_reduce (Conv2D  (None, 28, 28, 128)          65536     ['activation_67[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_4_1x1_reduce/bn (Bat  (None, 28, 28, 128)          512       ['conv3_4_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_68 (Activation)  (None, 28, 28, 128)          0         ['conv3_4_1x1_reduce/bn[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv3_4_3x3 (Conv2D)        (None, 28, 28, 128)          147456    ['activation_68[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_4_3x3/bn (BatchNorma  (None, 28, 28, 128)          512       ['conv3_4_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_69 (Activation)  (None, 28, 28, 128)          0         ['conv3_4_3x3/bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_4_1x1_increase (Conv  (None, 28, 28, 512)          65536     ['activation_69[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_4_1x1_increase/bn (B  (None, 28, 28, 512)          2048      ['conv3_4_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_22 (Add)                (None, 28, 28, 512)          0         ['conv3_4_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_67[0][0]']       \n",
      "                                                                                                  \n",
      " activation_70 (Activation)  (None, 28, 28, 512)          0         ['add_22[0][0]']              \n",
      "                                                                                                  \n",
      " conv4_1_1x1_reduce (Conv2D  (None, 14, 14, 256)          131072    ['activation_70[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_1_1x1_reduce/bn (Bat  (None, 14, 14, 256)          1024      ['conv4_1_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_71 (Activation)  (None, 14, 14, 256)          0         ['conv4_1_1x1_reduce/bn[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv4_1_3x3 (Conv2D)        (None, 14, 14, 256)          589824    ['activation_71[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_1_3x3/bn (BatchNorma  (None, 14, 14, 256)          1024      ['conv4_1_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_72 (Activation)  (None, 14, 14, 256)          0         ['conv4_1_3x3/bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_1_1x1_increase (Conv  (None, 14, 14, 1024)         262144    ['activation_72[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_1_1x1_proj (Conv2D)   (None, 14, 14, 1024)         524288    ['activation_70[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_1_1x1_increase/bn (B  (None, 14, 14, 1024)         4096      ['conv4_1_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv4_1_1x1_proj/bn (Batch  (None, 14, 14, 1024)         4096      ['conv4_1_1x1_proj[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_23 (Add)                (None, 14, 14, 1024)         0         ['conv4_1_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'conv4_1_1x1_proj/bn[0][0]'] \n",
      "                                                                                                  \n",
      " activation_73 (Activation)  (None, 14, 14, 1024)         0         ['add_23[0][0]']              \n",
      "                                                                                                  \n",
      " conv4_2_1x1_reduce (Conv2D  (None, 14, 14, 256)          262144    ['activation_73[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_2_1x1_reduce/bn (Bat  (None, 14, 14, 256)          1024      ['conv4_2_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_74 (Activation)  (None, 14, 14, 256)          0         ['conv4_2_1x1_reduce/bn[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv4_2_3x3 (Conv2D)        (None, 14, 14, 256)          589824    ['activation_74[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_2_3x3/bn (BatchNorma  (None, 14, 14, 256)          1024      ['conv4_2_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_75 (Activation)  (None, 14, 14, 256)          0         ['conv4_2_3x3/bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_2_1x1_increase (Conv  (None, 14, 14, 1024)         262144    ['activation_75[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_2_1x1_increase/bn (B  (None, 14, 14, 1024)         4096      ['conv4_2_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_24 (Add)                (None, 14, 14, 1024)         0         ['conv4_2_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_73[0][0]']       \n",
      "                                                                                                  \n",
      " activation_76 (Activation)  (None, 14, 14, 1024)         0         ['add_24[0][0]']              \n",
      "                                                                                                  \n",
      " conv4_3_1x1_reduce (Conv2D  (None, 14, 14, 256)          262144    ['activation_76[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_3_1x1_reduce/bn (Bat  (None, 14, 14, 256)          1024      ['conv4_3_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_77 (Activation)  (None, 14, 14, 256)          0         ['conv4_3_1x1_reduce/bn[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv4_3_3x3 (Conv2D)        (None, 14, 14, 256)          589824    ['activation_77[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_3_3x3/bn (BatchNorma  (None, 14, 14, 256)          1024      ['conv4_3_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_78 (Activation)  (None, 14, 14, 256)          0         ['conv4_3_3x3/bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_3_1x1_increase (Conv  (None, 14, 14, 1024)         262144    ['activation_78[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_3_1x1_increase/bn (B  (None, 14, 14, 1024)         4096      ['conv4_3_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_25 (Add)                (None, 14, 14, 1024)         0         ['conv4_3_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_76[0][0]']       \n",
      "                                                                                                  \n",
      " activation_79 (Activation)  (None, 14, 14, 1024)         0         ['add_25[0][0]']              \n",
      "                                                                                                  \n",
      " conv4_4_1x1_reduce (Conv2D  (None, 14, 14, 256)          262144    ['activation_79[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_4_1x1_reduce/bn (Bat  (None, 14, 14, 256)          1024      ['conv4_4_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_80 (Activation)  (None, 14, 14, 256)          0         ['conv4_4_1x1_reduce/bn[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv4_4_3x3 (Conv2D)        (None, 14, 14, 256)          589824    ['activation_80[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_4_3x3/bn (BatchNorma  (None, 14, 14, 256)          1024      ['conv4_4_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_81 (Activation)  (None, 14, 14, 256)          0         ['conv4_4_3x3/bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_4_1x1_increase (Conv  (None, 14, 14, 1024)         262144    ['activation_81[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_4_1x1_increase/bn (B  (None, 14, 14, 1024)         4096      ['conv4_4_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_26 (Add)                (None, 14, 14, 1024)         0         ['conv4_4_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_79[0][0]']       \n",
      "                                                                                                  \n",
      " activation_82 (Activation)  (None, 14, 14, 1024)         0         ['add_26[0][0]']              \n",
      "                                                                                                  \n",
      " conv4_5_1x1_reduce (Conv2D  (None, 14, 14, 256)          262144    ['activation_82[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_5_1x1_reduce/bn (Bat  (None, 14, 14, 256)          1024      ['conv4_5_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_83 (Activation)  (None, 14, 14, 256)          0         ['conv4_5_1x1_reduce/bn[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv4_5_3x3 (Conv2D)        (None, 14, 14, 256)          589824    ['activation_83[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_5_3x3/bn (BatchNorma  (None, 14, 14, 256)          1024      ['conv4_5_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_84 (Activation)  (None, 14, 14, 256)          0         ['conv4_5_3x3/bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_5_1x1_increase (Conv  (None, 14, 14, 1024)         262144    ['activation_84[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_5_1x1_increase/bn (B  (None, 14, 14, 1024)         4096      ['conv4_5_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_27 (Add)                (None, 14, 14, 1024)         0         ['conv4_5_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_82[0][0]']       \n",
      "                                                                                                  \n",
      " activation_85 (Activation)  (None, 14, 14, 1024)         0         ['add_27[0][0]']              \n",
      "                                                                                                  \n",
      " conv4_6_1x1_reduce (Conv2D  (None, 14, 14, 256)          262144    ['activation_85[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_6_1x1_reduce/bn (Bat  (None, 14, 14, 256)          1024      ['conv4_6_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_86 (Activation)  (None, 14, 14, 256)          0         ['conv4_6_1x1_reduce/bn[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv4_6_3x3 (Conv2D)        (None, 14, 14, 256)          589824    ['activation_86[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_6_3x3/bn (BatchNorma  (None, 14, 14, 256)          1024      ['conv4_6_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_87 (Activation)  (None, 14, 14, 256)          0         ['conv4_6_3x3/bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_6_1x1_increase (Conv  (None, 14, 14, 1024)         262144    ['activation_87[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_6_1x1_increase/bn (B  (None, 14, 14, 1024)         4096      ['conv4_6_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_28 (Add)                (None, 14, 14, 1024)         0         ['conv4_6_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_85[0][0]']       \n",
      "                                                                                                  \n",
      " activation_88 (Activation)  (None, 14, 14, 1024)         0         ['add_28[0][0]']              \n",
      "                                                                                                  \n",
      " conv5_1_1x1_reduce (Conv2D  (None, 7, 7, 512)            524288    ['activation_88[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_1_1x1_reduce/bn (Bat  (None, 7, 7, 512)            2048      ['conv5_1_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_89 (Activation)  (None, 7, 7, 512)            0         ['conv5_1_1x1_reduce/bn[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv5_1_3x3 (Conv2D)        (None, 7, 7, 512)            2359296   ['activation_89[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_1_3x3/bn (BatchNorma  (None, 7, 7, 512)            2048      ['conv5_1_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_90 (Activation)  (None, 7, 7, 512)            0         ['conv5_1_3x3/bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_1_1x1_increase (Conv  (None, 7, 7, 2048)           1048576   ['activation_90[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_1_1x1_proj (Conv2D)   (None, 7, 7, 2048)           2097152   ['activation_88[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_1_1x1_increase/bn (B  (None, 7, 7, 2048)           8192      ['conv5_1_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv5_1_1x1_proj/bn (Batch  (None, 7, 7, 2048)           8192      ['conv5_1_1x1_proj[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_29 (Add)                (None, 7, 7, 2048)           0         ['conv5_1_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'conv5_1_1x1_proj/bn[0][0]'] \n",
      "                                                                                                  \n",
      " activation_91 (Activation)  (None, 7, 7, 2048)           0         ['add_29[0][0]']              \n",
      "                                                                                                  \n",
      " conv5_2_1x1_reduce (Conv2D  (None, 7, 7, 512)            1048576   ['activation_91[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_2_1x1_reduce/bn (Bat  (None, 7, 7, 512)            2048      ['conv5_2_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_92 (Activation)  (None, 7, 7, 512)            0         ['conv5_2_1x1_reduce/bn[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv5_2_3x3 (Conv2D)        (None, 7, 7, 512)            2359296   ['activation_92[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_2_3x3/bn (BatchNorma  (None, 7, 7, 512)            2048      ['conv5_2_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_93 (Activation)  (None, 7, 7, 512)            0         ['conv5_2_3x3/bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_2_1x1_increase (Conv  (None, 7, 7, 2048)           1048576   ['activation_93[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_2_1x1_increase/bn (B  (None, 7, 7, 2048)           8192      ['conv5_2_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_30 (Add)                (None, 7, 7, 2048)           0         ['conv5_2_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_91[0][0]']       \n",
      "                                                                                                  \n",
      " activation_94 (Activation)  (None, 7, 7, 2048)           0         ['add_30[0][0]']              \n",
      "                                                                                                  \n",
      " conv5_3_1x1_reduce (Conv2D  (None, 7, 7, 512)            1048576   ['activation_94[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_3_1x1_reduce/bn (Bat  (None, 7, 7, 512)            2048      ['conv5_3_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_95 (Activation)  (None, 7, 7, 512)            0         ['conv5_3_1x1_reduce/bn[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv5_3_3x3 (Conv2D)        (None, 7, 7, 512)            2359296   ['activation_95[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_3_3x3/bn (BatchNorma  (None, 7, 7, 512)            2048      ['conv5_3_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_96 (Activation)  (None, 7, 7, 512)            0         ['conv5_3_3x3/bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_3_1x1_increase (Conv  (None, 7, 7, 2048)           1048576   ['activation_96[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_3_1x1_increase/bn (B  (None, 7, 7, 2048)           8192      ['conv5_3_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_31 (Add)                (None, 7, 7, 2048)           0         ['conv5_3_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_94[0][0]']       \n",
      "                                                                                                  \n",
      " activation_97 (Activation)  (None, 7, 7, 2048)           0         ['add_31[0][0]']              \n",
      "                                                                                                  \n",
      " avg_pool (AveragePooling2D  (None, 1, 1, 2048)           0         ['activation_97[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23561152 (89.88 MB)\n",
      "Trainable params: 23508032 (89.68 MB)\n",
      "Non-trainable params: 53120 (207.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.pooling.average_pooling2d.AveragePooling2D at 0x2845aa9ac50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model.get_layer('avg_pool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "seq = tf.keras.Sequential()\n",
    "seq.add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine import  Model\n",
    "from keras.layers import Flatten, Dense, Input\n",
    "from keras_vggface.vggface import VGGFace\n",
    "\n",
    "#custom parameters\n",
    "nb_class = 2\n",
    "hidden_dim = 512\n",
    "\n",
    "# Finetuning\n",
    "vgg_model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "last_layer = vgg_model.get_layer('avg_pool').output\n",
    "x = Flatten(name='flatten')(last_layer)\n",
    "x = Dense(hidden_dim, activation='relu', name='fc6')(x)\n",
    "x = Dense(hidden_dim, activation='relu', name='fc7')(x)\n",
    "out = Dense(nb_class, activation='softmax', name='fc8')(x)\n",
    "custom_vgg_model = Model([vgg_model.input, out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling build() or calling fit() with some data. Or specify input_shape or batch_input_shape in the first layer for automatic build. ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pedro\\OneDrive\\Documentos\\GitHub\\FaceRecognition_FeatureExtractor\\face_recognition.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/pedro/OneDrive/Documentos/GitHub/FaceRecognition_FeatureExtractor/face_recognition.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m custom_vgg_model\u001b[39m.\u001b[39;49msummary()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\engine\\network.py:1251\u001b[0m, in \u001b[0;36mNetwork.summary\u001b[1;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[0;32m   1235\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Prints a string summary of the network.\u001b[39;00m\n\u001b[0;32m   1236\u001b[0m \n\u001b[0;32m   1237\u001b[0m \u001b[39m# Arguments\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1248\u001b[0m \u001b[39m        It defaults to `print` (prints to stdout).\u001b[39;00m\n\u001b[0;32m   1249\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt:\n\u001b[1;32m-> 1251\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1252\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mThis model has not yet been built. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1253\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mBuild the model first by calling build() \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1254\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mor calling fit() with some data. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1255\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mOr specify input_shape or batch_input_shape \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1256\u001b[0m         \u001b[39m'\u001b[39m\u001b[39min the first layer for automatic build. \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1257\u001b[0m \u001b[39mreturn\u001b[39;00m print_layer_summary(\u001b[39mself\u001b[39m,\n\u001b[0;32m   1258\u001b[0m                            line_length\u001b[39m=\u001b[39mline_length,\n\u001b[0;32m   1259\u001b[0m                            positions\u001b[39m=\u001b[39mpositions,\n\u001b[0;32m   1260\u001b[0m                            print_fn\u001b[39m=\u001b[39mprint_fn)\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling build() or calling fit() with some data. Or specify input_shape or batch_input_shape in the first layer for automatic build. "
     ]
    }
   ],
   "source": [
    "custom_vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 381ms/step\n",
      "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_labels_v1.npy\n",
      "352256/346184 [==============================] - 0s 1us/step\n",
      "Predicted: [[[\"b'Jim_Henson'\", 0.018972041], [\"b'James_Cosmo'\", 0.010616946], [\"b'Nancy_Allen'\", 0.010168507], [\"b'Abraham_Benrubi'\", 0.009017848], [\"b'Jason_Mantzoukas'\", 0.007988723]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface import utils\n",
    "\n",
    "# tensorflow\n",
    "model = VGGFace() # default : VGG16 , you can use model='resnet50' or 'senet50'\n",
    "\n",
    "# Change the image path with yours.\n",
    "img = image.load_img('lacto.jpg', target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = utils.preprocess_input(x, version=1) # or version=2\n",
    "preds = model.predict(x)\n",
    "print('Predicted:', utils.decode_predictions(preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
