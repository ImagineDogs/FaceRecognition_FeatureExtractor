{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/rcmalli/keras-vggface.gitNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/rcmalli/keras-vggface.git 'C:\\Users\\pedro\\AppData\\Local\\Temp\\pip-req-build-dntam2es'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Cloning https://github.com/rcmalli/keras-vggface.git to c:\\users\\pedro\\appdata\\local\\temp\\pip-req-build-dntam2es\n",
      "  Resolved https://github.com/rcmalli/keras-vggface.git to commit bee35376e76e35d00aeec503f2f242611a97b38a\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\python311\\lib\\site-packages (from keras-vggface==0.6) (1.25.2)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\python311\\lib\\site-packages (from keras-vggface==0.6) (1.11.2)\n",
      "Requirement already satisfied: h5py in c:\\python311\\lib\\site-packages (from keras-vggface==0.6) (3.9.0)\n",
      "Requirement already satisfied: pillow in c:\\python311\\lib\\site-packages (from keras-vggface==0.6) (10.0.0)\n",
      "Requirement already satisfied: keras in c:\\python311\\lib\\site-packages (from keras-vggface==0.6) (2.2.4)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\pedro\\appdata\\roaming\\python\\python311\\site-packages (from keras-vggface==0.6) (1.16.0)\n",
      "Requirement already satisfied: pyyaml in c:\\python311\\lib\\site-packages (from keras-vggface==0.6) (6.0.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\python311\\lib\\site-packages (from keras->keras-vggface==0.6) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\python311\\lib\\site-packages (from keras->keras-vggface==0.6) (1.1.2)\n",
      "Requirement already satisfied: keras==2.2.4 in c:\\python311\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\python311\\lib\\site-packages (from keras==2.2.4) (1.25.2)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\python311\\lib\\site-packages (from keras==2.2.4) (1.11.2)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\pedro\\appdata\\roaming\\python\\python311\\site-packages (from keras==2.2.4) (1.16.0)\n",
      "Requirement already satisfied: pyyaml in c:\\python311\\lib\\site-packages (from keras==2.2.4) (6.0.1)\n",
      "Requirement already satisfied: h5py in c:\\python311\\lib\\site-packages (from keras==2.2.4) (3.9.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\python311\\lib\\site-packages (from keras==2.2.4) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\python311\\lib\\site-packages (from keras==2.2.4) (1.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Iterable' from 'collections' (c:\\Python311\\Lib\\collections\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pedro\\OneDrive\\Documentos\\GitHub\\FaceRecognition_FeatureExtractor\\face_recognition.ipynb Cell 1\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pedro/OneDrive/Documentos/GitHub/FaceRecognition_FeatureExtractor/face_recognition.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mpip\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minstall keras==2.2.4\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pedro/OneDrive/Documentos/GitHub/FaceRecognition_FeatureExtractor/face_recognition.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# %pip install tensorflow==1.14.0\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/pedro/OneDrive/Documentos/GitHub/FaceRecognition_FeatureExtractor/face_recognition.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_vggface\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvggface\u001b[39;00m \u001b[39mimport\u001b[39;00m VGGFace\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras_vggface\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_vggface\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvggface\u001b[39;00m \u001b[39mimport\u001b[39;00m VGGFace\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_vggface\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversion\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras_vggface\\vggface.py:9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m'''VGGFace models for Keras.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[39m# Reference:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function\n\u001b[1;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_vggface\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m RESNET50, VGG16, SENET50\n\u001b[0;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mVGGFace\u001b[39m(include_top\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, model\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvgg16\u001b[39m\u001b[39m'\u001b[39m, weights\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvggface\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     13\u001b[0m             input_tensor\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, input_shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     14\u001b[0m             pooling\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     15\u001b[0m             classes\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     16\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Instantiates the VGGFace architectures.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m    Optionally loads weights pre-trained\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m    on VGGFace datasets. Note that when using TensorFlow,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[39m            or invalid input shape.\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras_vggface\\models.py:12\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m'''VGGFace models for Keras.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[39m# Notes:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Flatten, Dense, Input, GlobalAveragePooling2D, \\\n\u001b[0;32m     13\u001b[0m     GlobalMaxPooling2D, Activation, Conv2D, MaxPooling2D, BatchNormalization, \\\n\u001b[0;32m     14\u001b[0m     AveragePooling2D, Reshape, Permute, multiply\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras_applications\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimagenet_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m _obtain_input_shape\n\u001b[0;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m layer_utils\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m absolute_import\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m utils\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m activations\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m applications\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\utils\\__init__.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mnp_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m to_categorical\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mnp_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m normalize\n\u001b[1;32m---> 27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmulti_gpu_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m multi_gpu_model\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\utils\\multi_gpu_utils.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m division\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmerge\u001b[39;00m \u001b[39mimport\u001b[39;00m concatenate\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m backend \u001b[39mas\u001b[39;00m K\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m Lambda\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\layers\\__init__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m absolute_import\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneric_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m deserialize_keras_object\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Layer\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m InputLayer\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\engine\\__init__.py:8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Layer\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mnetwork\u001b[39;00m \u001b[39mimport\u001b[39;00m get_source_inputs\n\u001b[1;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtraining\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\engine\\training.py:21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtraining_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m standardize_weights\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtraining_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m weighted_masked_objective\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m training_arrays\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m training_generator\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m backend \u001b[39mas\u001b[39;00m K\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\engine\\training_arrays.py:14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtraining_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m check_num_samples\n\u001b[0;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m backend \u001b[39mas\u001b[39;00m K\n\u001b[1;32m---> 14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m callbacks \u001b[39mas\u001b[39;00m cbks\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneric_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m Progbar\n\u001b[0;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneric_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m slice_arrays\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\callbacks.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m deque\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m OrderedDict\n\u001b[1;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m Iterable\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneric_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m Progbar\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m backend \u001b[39mas\u001b[39;00m K\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Iterable' from 'collections' (c:\\Python311\\Lib\\collections\\__init__.py)"
     ]
    }
   ],
   "source": [
    "%pip install git+https://github.com/rcmalli/keras-vggface.git\n",
    "%pip install keras==2.2.4\n",
    "# %pip install tensorflow==1.14.0\n",
    "from keras_vggface.vggface import VGGFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "vggface = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3)) # or VGGFace() as default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x00000284864C5760> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function trace_model_call.<locals>._wrapped_model at 0x00000284864C5760>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x00000284864C5760> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function trace_model_call.<locals>._wrapped_model at 0x00000284864C5760>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x00000284864C5760> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function trace_model_call.<locals>._wrapped_model at 0x00000284864C5760>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: resnet_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: resnet_model\\assets\n"
     ]
    }
   ],
   "source": [
    "vggface.save('resnet_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# model = tf.keras.applications.resnet50.ResNet50(include_top=False, weights=None)\n",
    "mod = tf.keras.models.load_model('resnet_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_class = 2\n",
    "hidden_dim = 512\n",
    "# seq = tf.keras.Sequential(mod)\n",
    "\n",
    "last_layer = mod.get_layer('avg_pool').output\n",
    "x = tf.keras.layers.Flatten(name='flatten')(last_layer)\n",
    "x = tf.keras.layers.Dense(hidden_dim, activation='relu', name='fc6')(x)\n",
    "x = tf.keras.layers.Dense(hidden_dim, activation='relu', name='fc7')(x)\n",
    "out = tf.keras.layers.Dense(nb_class, activation='softmax', name='fc8')(x)\n",
    "\n",
    "custom_vgg_model = tf.keras.Model(mod.input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_17 (InputLayer)       [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv1/7x7_s2 (Conv2D)       (None, 112, 112, 64)         9408      ['input_17[0][0]']            \n",
      "                                                                                                  \n",
      " conv1/7x7_s2/bn (BatchNorm  (None, 112, 112, 64)         256       ['conv1/7x7_s2[0][0]']        \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation_441 (Activation  (None, 112, 112, 64)         0         ['conv1/7x7_s2/bn[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPoolin  (None, 55, 55, 64)           0         ['activation_441[0][0]']      \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_1_1x1_reduce (Conv2D  (None, 55, 55, 64)           4096      ['max_pooling2d_9[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_1_1x1_reduce/bn (Bat  (None, 55, 55, 64)           256       ['conv2_1_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_442 (Activation  (None, 55, 55, 64)           0         ['conv2_1_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv2_1_3x3 (Conv2D)        (None, 55, 55, 64)           36864     ['activation_442[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_1_3x3/bn (BatchNorma  (None, 55, 55, 64)           256       ['conv2_1_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_443 (Activation  (None, 55, 55, 64)           0         ['conv2_1_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_1_1x1_increase (Conv  (None, 55, 55, 256)          16384     ['activation_443[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv2_1_1x1_proj (Conv2D)   (None, 55, 55, 256)          16384     ['max_pooling2d_9[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_1_1x1_increase/bn (B  (None, 55, 55, 256)          1024      ['conv2_1_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2_1_1x1_proj/bn (Batch  (None, 55, 55, 256)          1024      ['conv2_1_1x1_proj[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_144 (Add)               (None, 55, 55, 256)          0         ['conv2_1_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'conv2_1_1x1_proj/bn[0][0]'] \n",
      "                                                                                                  \n",
      " activation_444 (Activation  (None, 55, 55, 256)          0         ['add_144[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_2_1x1_reduce (Conv2D  (None, 55, 55, 64)           16384     ['activation_444[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_2_1x1_reduce/bn (Bat  (None, 55, 55, 64)           256       ['conv2_2_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_445 (Activation  (None, 55, 55, 64)           0         ['conv2_2_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv2_2_3x3 (Conv2D)        (None, 55, 55, 64)           36864     ['activation_445[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_2_3x3/bn (BatchNorma  (None, 55, 55, 64)           256       ['conv2_2_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_446 (Activation  (None, 55, 55, 64)           0         ['conv2_2_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_2_1x1_increase (Conv  (None, 55, 55, 256)          16384     ['activation_446[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv2_2_1x1_increase/bn (B  (None, 55, 55, 256)          1024      ['conv2_2_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_145 (Add)               (None, 55, 55, 256)          0         ['conv2_2_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_444[0][0]']      \n",
      "                                                                                                  \n",
      " activation_447 (Activation  (None, 55, 55, 256)          0         ['add_145[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_3_1x1_reduce (Conv2D  (None, 55, 55, 64)           16384     ['activation_447[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_3_1x1_reduce/bn (Bat  (None, 55, 55, 64)           256       ['conv2_3_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_448 (Activation  (None, 55, 55, 64)           0         ['conv2_3_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv2_3_3x3 (Conv2D)        (None, 55, 55, 64)           36864     ['activation_448[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_3_3x3/bn (BatchNorma  (None, 55, 55, 64)           256       ['conv2_3_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_449 (Activation  (None, 55, 55, 64)           0         ['conv2_3_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_3_1x1_increase (Conv  (None, 55, 55, 256)          16384     ['activation_449[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv2_3_1x1_increase/bn (B  (None, 55, 55, 256)          1024      ['conv2_3_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_146 (Add)               (None, 55, 55, 256)          0         ['conv2_3_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_447[0][0]']      \n",
      "                                                                                                  \n",
      " activation_450 (Activation  (None, 55, 55, 256)          0         ['add_146[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_1_1x1_reduce (Conv2D  (None, 28, 28, 128)          32768     ['activation_450[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_1_1x1_reduce/bn (Bat  (None, 28, 28, 128)          512       ['conv3_1_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_451 (Activation  (None, 28, 28, 128)          0         ['conv3_1_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv3_1_3x3 (Conv2D)        (None, 28, 28, 128)          147456    ['activation_451[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_1_3x3/bn (BatchNorma  (None, 28, 28, 128)          512       ['conv3_1_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_452 (Activation  (None, 28, 28, 128)          0         ['conv3_1_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_1_1x1_increase (Conv  (None, 28, 28, 512)          65536     ['activation_452[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_1_1x1_proj (Conv2D)   (None, 28, 28, 512)          131072    ['activation_450[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_1_1x1_increase/bn (B  (None, 28, 28, 512)          2048      ['conv3_1_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv3_1_1x1_proj/bn (Batch  (None, 28, 28, 512)          2048      ['conv3_1_1x1_proj[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_147 (Add)               (None, 28, 28, 512)          0         ['conv3_1_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'conv3_1_1x1_proj/bn[0][0]'] \n",
      "                                                                                                  \n",
      " activation_453 (Activation  (None, 28, 28, 512)          0         ['add_147[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_2_1x1_reduce (Conv2D  (None, 28, 28, 128)          65536     ['activation_453[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_2_1x1_reduce/bn (Bat  (None, 28, 28, 128)          512       ['conv3_2_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_454 (Activation  (None, 28, 28, 128)          0         ['conv3_2_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv3_2_3x3 (Conv2D)        (None, 28, 28, 128)          147456    ['activation_454[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_2_3x3/bn (BatchNorma  (None, 28, 28, 128)          512       ['conv3_2_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_455 (Activation  (None, 28, 28, 128)          0         ['conv3_2_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_2_1x1_increase (Conv  (None, 28, 28, 512)          65536     ['activation_455[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_2_1x1_increase/bn (B  (None, 28, 28, 512)          2048      ['conv3_2_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_148 (Add)               (None, 28, 28, 512)          0         ['conv3_2_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_453[0][0]']      \n",
      "                                                                                                  \n",
      " activation_456 (Activation  (None, 28, 28, 512)          0         ['add_148[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_3_1x1_reduce (Conv2D  (None, 28, 28, 128)          65536     ['activation_456[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_3_1x1_reduce/bn (Bat  (None, 28, 28, 128)          512       ['conv3_3_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_457 (Activation  (None, 28, 28, 128)          0         ['conv3_3_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv3_3_3x3 (Conv2D)        (None, 28, 28, 128)          147456    ['activation_457[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_3_3x3/bn (BatchNorma  (None, 28, 28, 128)          512       ['conv3_3_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_458 (Activation  (None, 28, 28, 128)          0         ['conv3_3_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_3_1x1_increase (Conv  (None, 28, 28, 512)          65536     ['activation_458[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_3_1x1_increase/bn (B  (None, 28, 28, 512)          2048      ['conv3_3_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_149 (Add)               (None, 28, 28, 512)          0         ['conv3_3_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_456[0][0]']      \n",
      "                                                                                                  \n",
      " activation_459 (Activation  (None, 28, 28, 512)          0         ['add_149[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_4_1x1_reduce (Conv2D  (None, 28, 28, 128)          65536     ['activation_459[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_4_1x1_reduce/bn (Bat  (None, 28, 28, 128)          512       ['conv3_4_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_460 (Activation  (None, 28, 28, 128)          0         ['conv3_4_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv3_4_3x3 (Conv2D)        (None, 28, 28, 128)          147456    ['activation_460[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_4_3x3/bn (BatchNorma  (None, 28, 28, 128)          512       ['conv3_4_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_461 (Activation  (None, 28, 28, 128)          0         ['conv3_4_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_4_1x1_increase (Conv  (None, 28, 28, 512)          65536     ['activation_461[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_4_1x1_increase/bn (B  (None, 28, 28, 512)          2048      ['conv3_4_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_150 (Add)               (None, 28, 28, 512)          0         ['conv3_4_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_459[0][0]']      \n",
      "                                                                                                  \n",
      " activation_462 (Activation  (None, 28, 28, 512)          0         ['add_150[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_1_1x1_reduce (Conv2D  (None, 14, 14, 256)          131072    ['activation_462[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_1_1x1_reduce/bn (Bat  (None, 14, 14, 256)          1024      ['conv4_1_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_463 (Activation  (None, 14, 14, 256)          0         ['conv4_1_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv4_1_3x3 (Conv2D)        (None, 14, 14, 256)          589824    ['activation_463[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_1_3x3/bn (BatchNorma  (None, 14, 14, 256)          1024      ['conv4_1_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_464 (Activation  (None, 14, 14, 256)          0         ['conv4_1_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_1_1x1_increase (Conv  (None, 14, 14, 1024)         262144    ['activation_464[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_1_1x1_proj (Conv2D)   (None, 14, 14, 1024)         524288    ['activation_462[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_1_1x1_increase/bn (B  (None, 14, 14, 1024)         4096      ['conv4_1_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv4_1_1x1_proj/bn (Batch  (None, 14, 14, 1024)         4096      ['conv4_1_1x1_proj[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_151 (Add)               (None, 14, 14, 1024)         0         ['conv4_1_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'conv4_1_1x1_proj/bn[0][0]'] \n",
      "                                                                                                  \n",
      " activation_465 (Activation  (None, 14, 14, 1024)         0         ['add_151[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_2_1x1_reduce (Conv2D  (None, 14, 14, 256)          262144    ['activation_465[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_2_1x1_reduce/bn (Bat  (None, 14, 14, 256)          1024      ['conv4_2_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_466 (Activation  (None, 14, 14, 256)          0         ['conv4_2_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv4_2_3x3 (Conv2D)        (None, 14, 14, 256)          589824    ['activation_466[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_2_3x3/bn (BatchNorma  (None, 14, 14, 256)          1024      ['conv4_2_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_467 (Activation  (None, 14, 14, 256)          0         ['conv4_2_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_2_1x1_increase (Conv  (None, 14, 14, 1024)         262144    ['activation_467[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_2_1x1_increase/bn (B  (None, 14, 14, 1024)         4096      ['conv4_2_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_152 (Add)               (None, 14, 14, 1024)         0         ['conv4_2_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_465[0][0]']      \n",
      "                                                                                                  \n",
      " activation_468 (Activation  (None, 14, 14, 1024)         0         ['add_152[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_3_1x1_reduce (Conv2D  (None, 14, 14, 256)          262144    ['activation_468[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_3_1x1_reduce/bn (Bat  (None, 14, 14, 256)          1024      ['conv4_3_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_469 (Activation  (None, 14, 14, 256)          0         ['conv4_3_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv4_3_3x3 (Conv2D)        (None, 14, 14, 256)          589824    ['activation_469[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_3_3x3/bn (BatchNorma  (None, 14, 14, 256)          1024      ['conv4_3_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_470 (Activation  (None, 14, 14, 256)          0         ['conv4_3_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_3_1x1_increase (Conv  (None, 14, 14, 1024)         262144    ['activation_470[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_3_1x1_increase/bn (B  (None, 14, 14, 1024)         4096      ['conv4_3_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_153 (Add)               (None, 14, 14, 1024)         0         ['conv4_3_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_468[0][0]']      \n",
      "                                                                                                  \n",
      " activation_471 (Activation  (None, 14, 14, 1024)         0         ['add_153[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_4_1x1_reduce (Conv2D  (None, 14, 14, 256)          262144    ['activation_471[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_4_1x1_reduce/bn (Bat  (None, 14, 14, 256)          1024      ['conv4_4_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_472 (Activation  (None, 14, 14, 256)          0         ['conv4_4_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv4_4_3x3 (Conv2D)        (None, 14, 14, 256)          589824    ['activation_472[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_4_3x3/bn (BatchNorma  (None, 14, 14, 256)          1024      ['conv4_4_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_473 (Activation  (None, 14, 14, 256)          0         ['conv4_4_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_4_1x1_increase (Conv  (None, 14, 14, 1024)         262144    ['activation_473[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_4_1x1_increase/bn (B  (None, 14, 14, 1024)         4096      ['conv4_4_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_154 (Add)               (None, 14, 14, 1024)         0         ['conv4_4_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_471[0][0]']      \n",
      "                                                                                                  \n",
      " activation_474 (Activation  (None, 14, 14, 1024)         0         ['add_154[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_5_1x1_reduce (Conv2D  (None, 14, 14, 256)          262144    ['activation_474[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_5_1x1_reduce/bn (Bat  (None, 14, 14, 256)          1024      ['conv4_5_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_475 (Activation  (None, 14, 14, 256)          0         ['conv4_5_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv4_5_3x3 (Conv2D)        (None, 14, 14, 256)          589824    ['activation_475[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_5_3x3/bn (BatchNorma  (None, 14, 14, 256)          1024      ['conv4_5_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_476 (Activation  (None, 14, 14, 256)          0         ['conv4_5_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_5_1x1_increase (Conv  (None, 14, 14, 1024)         262144    ['activation_476[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_5_1x1_increase/bn (B  (None, 14, 14, 1024)         4096      ['conv4_5_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_155 (Add)               (None, 14, 14, 1024)         0         ['conv4_5_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_474[0][0]']      \n",
      "                                                                                                  \n",
      " activation_477 (Activation  (None, 14, 14, 1024)         0         ['add_155[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_6_1x1_reduce (Conv2D  (None, 14, 14, 256)          262144    ['activation_477[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_6_1x1_reduce/bn (Bat  (None, 14, 14, 256)          1024      ['conv4_6_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_478 (Activation  (None, 14, 14, 256)          0         ['conv4_6_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv4_6_3x3 (Conv2D)        (None, 14, 14, 256)          589824    ['activation_478[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_6_3x3/bn (BatchNorma  (None, 14, 14, 256)          1024      ['conv4_6_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_479 (Activation  (None, 14, 14, 256)          0         ['conv4_6_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_6_1x1_increase (Conv  (None, 14, 14, 1024)         262144    ['activation_479[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_6_1x1_increase/bn (B  (None, 14, 14, 1024)         4096      ['conv4_6_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_156 (Add)               (None, 14, 14, 1024)         0         ['conv4_6_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_477[0][0]']      \n",
      "                                                                                                  \n",
      " activation_480 (Activation  (None, 14, 14, 1024)         0         ['add_156[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_1_1x1_reduce (Conv2D  (None, 7, 7, 512)            524288    ['activation_480[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_1_1x1_reduce/bn (Bat  (None, 7, 7, 512)            2048      ['conv5_1_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_481 (Activation  (None, 7, 7, 512)            0         ['conv5_1_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv5_1_3x3 (Conv2D)        (None, 7, 7, 512)            2359296   ['activation_481[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_1_3x3/bn (BatchNorma  (None, 7, 7, 512)            2048      ['conv5_1_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_482 (Activation  (None, 7, 7, 512)            0         ['conv5_1_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_1_1x1_increase (Conv  (None, 7, 7, 2048)           1048576   ['activation_482[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_1_1x1_proj (Conv2D)   (None, 7, 7, 2048)           2097152   ['activation_480[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_1_1x1_increase/bn (B  (None, 7, 7, 2048)           8192      ['conv5_1_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv5_1_1x1_proj/bn (Batch  (None, 7, 7, 2048)           8192      ['conv5_1_1x1_proj[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_157 (Add)               (None, 7, 7, 2048)           0         ['conv5_1_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'conv5_1_1x1_proj/bn[0][0]'] \n",
      "                                                                                                  \n",
      " activation_483 (Activation  (None, 7, 7, 2048)           0         ['add_157[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_2_1x1_reduce (Conv2D  (None, 7, 7, 512)            1048576   ['activation_483[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_2_1x1_reduce/bn (Bat  (None, 7, 7, 512)            2048      ['conv5_2_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_484 (Activation  (None, 7, 7, 512)            0         ['conv5_2_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv5_2_3x3 (Conv2D)        (None, 7, 7, 512)            2359296   ['activation_484[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_2_3x3/bn (BatchNorma  (None, 7, 7, 512)            2048      ['conv5_2_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_485 (Activation  (None, 7, 7, 512)            0         ['conv5_2_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_2_1x1_increase (Conv  (None, 7, 7, 2048)           1048576   ['activation_485[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_2_1x1_increase/bn (B  (None, 7, 7, 2048)           8192      ['conv5_2_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_158 (Add)               (None, 7, 7, 2048)           0         ['conv5_2_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_483[0][0]']      \n",
      "                                                                                                  \n",
      " activation_486 (Activation  (None, 7, 7, 2048)           0         ['add_158[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_3_1x1_reduce (Conv2D  (None, 7, 7, 512)            1048576   ['activation_486[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_3_1x1_reduce/bn (Bat  (None, 7, 7, 512)            2048      ['conv5_3_1x1_reduce[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_487 (Activation  (None, 7, 7, 512)            0         ['conv5_3_1x1_reduce/bn[0][0]'\n",
      " )                                                                  ]                             \n",
      "                                                                                                  \n",
      " conv5_3_3x3 (Conv2D)        (None, 7, 7, 512)            2359296   ['activation_487[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_3_3x3/bn (BatchNorma  (None, 7, 7, 512)            2048      ['conv5_3_3x3[0][0]']         \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_488 (Activation  (None, 7, 7, 512)            0         ['conv5_3_3x3/bn[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv5_3_1x1_increase (Conv  (None, 7, 7, 2048)           1048576   ['activation_488[0][0]']      \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_3_1x1_increase/bn (B  (None, 7, 7, 2048)           8192      ['conv5_3_1x1_increase[0][0]']\n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_159 (Add)               (None, 7, 7, 2048)           0         ['conv5_3_1x1_increase/bn[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'activation_486[0][0]']      \n",
      "                                                                                                  \n",
      " activation_489 (Activation  (None, 7, 7, 2048)           0         ['add_159[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " avg_pool (AveragePooling2D  (None, 1, 1, 2048)           0         ['activation_489[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 2048)                 0         ['avg_pool[0][0]']            \n",
      "                                                                                                  \n",
      " fc6 (Dense)                 (None, 512)                  1049088   ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " fc7 (Dense)                 (None, 512)                  262656    ['fc6[0][0]']                 \n",
      "                                                                                                  \n",
      " fc8 (Dense)                 (None, 2)                    1026      ['fc7[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 24873922 (94.89 MB)\n",
      "Trainable params: 24820802 (94.68 MB)\n",
      "Non-trainable params: 53120 (207.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "custom_vgg_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinar inicialmente com todos as camadas treinaveis\n",
    "Para adicionar novas pessoas, adicionar uma classe extra na camada final e treinar apenas a ultima camada."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
